ğŸ“˜ End-to-End Spam Classification with DVC (Production-Grade, Step by Step)
This document is a complete, corrected, and production-aligned guide to building an end-to-end ML pipeline using DVC for a Spam Identification problem.
It reflects the latest working state of our project, including: - Correct feature engineering - Proper train/test split - Correct evaluation logic - A clean, valid DVC DAG - Real-world MLOps explanations (what, why, how)
This README is written as if you are onboarding a new MLOps engineer onto the project.

ğŸ§© Problem Statement
We want to build a Spam Classification ML system.
Input: Text message
Output: Spam (1) or Not Spam (0)
The focus is not just accuracy, but: - Reproducibility - Versioning - Automation - CI/CD readiness

ğŸ—ï¸ Final Project Structure
spam-mlops/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ spam.csv                # Immutable raw data
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ ingested.csv            # Ingestion checkpoint
â”‚       â”œâ”€â”€ clean.csv               # Cleaned data
â”‚       â”œâ”€â”€ features.pkl            # TF-IDF features
â”‚       â”œâ”€â”€ train.pkl               # Training split
â”‚       â””â”€â”€ test.pkl                # Test split
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”œâ”€â”€ data_processing.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ train_test_split.py
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ evaluation.py
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ vectorizer.pkl              # Text â†’ numeric transformer
â”‚   â””â”€â”€ model.pkl                   # Trained ML model
â”‚
â”œâ”€â”€ dvclive/
â”‚   â””â”€â”€ metrics.json                # Evaluation metrics
â”‚
â”œâ”€â”€ dvc.yaml                        # Pipeline definition
â”œâ”€â”€ dvc.lock                        # Reproducibility contract
â””â”€â”€ README.md

ğŸ” High-Level Pipeline Flow
Raw Data
   â†“
Data Ingestion
   â†“
Data Processing
   â†“
Feature Engineering
   â†“
Train/Test Split
   â†“
Model Training
   â†“
Model Evaluation
Each arrow represents a DVC stage boundary.

ğŸ§  Why We Use DVC Here
DVC provides: - Git-like versioning for data & models - Reproducible ML pipelines - Hash-based dependency tracking - CI/CD-friendly execution
â— DVC tracks files, not in-memory variables.

1ï¸âƒ£ Data Ingestion Stage
ğŸ“„ src/data_ingestion.py
import pandas as pd

# Read raw data (source of truth)
df = pd.read_csv("data/raw/spam.csv")

# Write ingestion checkpoint
# This creates a pipeline boundary
df.to_csv("data/processed/ingested.csv", index=False)
ğŸ§  Explanation
No transformation happens here
The file may look identical to raw data â€” this is expected
Purpose:
Validate data can be read
Decouple downstream stages from raw source

2ï¸âƒ£ Data Processing Stage
ğŸ“„ src/data_processing.py
import pandas as pd

df = pd.read_csv("data/processed/ingested.csv")

# Ensure labels are numeric
df["label"] = df["label"].astype(int)

# Save cleaned data
df.to_csv("data/processed/clean.csv", index=False)
ğŸ§  Explanation
This stage is responsible for: - Type enforcement - Validation - Cleaning
In real projects, this is where: - Missing values - Schema checks - Deduplication
would live.

3ï¸âƒ£ Feature Engineering Stage (CRITICAL)
ğŸ“„ src/feature_engineering.py
from sklearn.feature_extraction.text import TfidfVectorizer
import pandas as pd
import pickle
import os

# Load cleaned data
df = pd.read_csv("data/processed/clean.csv")

# Convert text to numeric features
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(df["text"])

y = df["label"]

# Ensure output directories exist
os.makedirs("models", exist_ok=True)

# Save vectorizer for inference
with open("models/vectorizer.pkl", "wb") as f:
    pickle.dump(vectorizer, f)

# Save features for training stage
with open("data/processed/features.pkl", "wb") as f:
    pickle.dump((X, y), f)
ğŸ§  Explanation (Line by Line)
ML models cannot read text
TF-IDF converts text â†’ numbers
Vectorizer must be saved for inference
Features must be written to disk for DVC tracking
This stage is where ML truly begins.

4ï¸âƒ£ Train/Test Split Stage
ğŸ“„ src/train_test_split.py
import pickle
from sklearn.model_selection import train_test_split

X, y = pickle.load(open("data/processed/features.pkl", "rb"))

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42
)

with open("data/processed/train.pkl", "wb") as f:
    pickle.dump((X_train, y_train), f)

with open("data/processed/test.pkl", "wb") as f:
    pickle.dump((X_test, y_test), f)
ğŸ§  Why This Is a Separate Stage
Changing test size should NOT recompute features
This separation enables efficient experiments

5ï¸âƒ£ Model Training Stage
ğŸ“„ src/train.py
import pickle
from sklearn.linear_model import LogisticRegression
import os

X_train, y_train = pickle.load(
    open("data/processed/train.pkl", "rb")
)

model = LogisticRegression()
model.fit(X_train, y_train)

os.makedirs("models", exist_ok=True)
pickle.dump(model, open("models/model.pkl", "wb"))
ğŸ§  Explanation
Training uses ONLY training data
Output is a versioned model artifact

6ï¸âƒ£ Model Evaluation Stage
ğŸ“„ src/evaluation.py
import pickle
from sklearn.metrics import accuracy_score
from dvclive import Live

model = pickle.load(open("models/model.pkl", "rb"))
X_test, y_test = pickle.load(
    open("data/processed/test.pkl", "rb")
)

preds = model.predict(X_test)

with Live() as live:
    live.log_metric("accuracy", accuracy_score(y_test, preds))
ğŸ§  Explanation
Evaluation uses unseen test data
Metrics are logged via DVCLive
DVC versions metrics automatically

7ï¸âƒ£ DVC Pipeline Definition (dvc.yaml)
stages:
  ingest:
    cmd: python src/data_ingestion.py
    deps:
      - src/data_ingestion.py
      - data/raw/spam.csv
    outs:
      - data/processed/ingested.csv

  process:
    cmd: python src/data_processing.py
    deps:
      - src/data_processing.py
      - data/processed/ingested.csv
    outs:
      - data/processed/clean.csv

  features:
    cmd: python src/feature_engineering.py
    deps:
      - src/feature_engineering.py
      - data/processed/clean.csv
    outs:
      - data/processed/features.pkl
      - models/vectorizer.pkl

  split:
    cmd: python src/train_test_split.py
    deps:
      - src/train_test_split.py
      - data/processed/features.pkl
    outs:
      - data/processed/train.pkl
      - data/processed/test.pkl

  train:
    cmd: python src/train.py
    deps:
      - src/train.py
      - data/processed/train.pkl
    outs:
      - models/model.pkl

  evaluate:
    cmd: python src/evaluation.py
    deps:
      - src/evaluation.py
      - models/model.pkl
      - data/processed/test.pkl
    metrics:
      - dvclive/metrics.json

8ï¸âƒ£ DVC DAG (Validated)
dvc dag
Confirms: - Correct dependencies - Proper branching - CI-safe execution order

9ï¸âƒ£ How to Run the Project (Correct Way)
dvc repro
DO NOT run individual scripts in production.

ğŸ” Reproducibility Guarantee
dvc.lock captures exact hashes
Same inputs â†’ same outputs
Works across machines and CI systems

âœ… Key Takeaways
DVC enforces correct ML architecture
Each stage has a clear contract
Pipelines are reproducible and debuggable
This setup is production-ready

ğŸš€ Next Steps
params.yaml for hyperparameters
dvc exp run for experiments
GitHub Actions CI
MLflow integration
Deployment with FastAPI + Docker

ğŸ‘¨â€ğŸ« You now have a real-world MLOps-ready DVC project.
